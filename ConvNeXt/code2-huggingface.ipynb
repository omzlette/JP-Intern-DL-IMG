{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Image Classification with ConvNeXt**\n",
    "\n",
    "Written By: Tharnarch Thoranisttakul\n",
    "\n",
    "This project is for the internship program in Japan at Kanazawa University.\n",
    "\n",
    "The topic is as stated above. Firstly, we will take a look at classifying image with ConvNeXt. Then, we will take a look at classifying image with Transformers (if we have time then we will take a look at Transformers).\n",
    "\n",
    "Right now, we will only focus on **ConvNeXt**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Exploration**\n",
    "\n",
    "The task from this lab was to use **CIFAR-100** as the dataset for image classificatoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List\n",
    "from tqdm.notebook import tqdm\n",
    "import glob\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Import scikit-learn libraries and packages\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Import PyTorch libraries and packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split, TensorDataset, Dataset\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet50, ConvNeXt, ConvNeXt_Base_Weights\n",
    "from torchvision.ops import StochasticDepth\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract dataset\n",
    "# Uncomment the code below to extract the dataset\n",
    "# !tar xvzf data/cifar-100-python.tar.gz -C data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train = unpickle('data/cifar-100-python/train')\n",
    "test = unpickle('data/cifar-100-python/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Train Keys: {train.keys()}\\nTest Keys: {test.keys()}')\n",
    "print('-'*20)\n",
    "print(f'Train Data Shape: {train[b\"data\"].shape}\\nTest Data Shape: {test[b\"data\"].shape}')\n",
    "print('-'*20)\n",
    "print(f'Train Data Type: {type(train[b\"data\"])}\\nTest Data Type: {type(test[b\"data\"])}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Dataset Description**\n",
    "\n",
    "From the [official website](https://www.cs.toronto.edu/~kriz/cifar.html), the CIFAR-100 dataset contains 100 classes. Each class contains 600 images each, 500 of which are training images and the rest are testing images.\n",
    "\n",
    "Similarly to CIFAR-10, the data shape is a 60000x3072 numpy array. This corresponds to the code and description above, which is 500 training images and 100 testing images in each class, resulting in a grand total of 50000x3072 and 10000x3072 numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Train Coarse Labels: {train[b\"coarse_labels\"]}\\nTest Coarse Labels: {test[b\"coarse_labels\"]}')\n",
    "print('-'*20)\n",
    "print(f'Train Fine Labels: {train[b\"fine_labels\"]}\\nTest Fine Labels: {test[b\"fine_labels\"]}')\n",
    "print('-'*20)\n",
    "print(f'Train Batch Label: {train[b\"batch_label\"]}\\nTest Batch Label: {test[b\"batch_label\"]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fine labels are classes, while the coarse labels are superclasses stated below.\n",
    "\n",
    "|**Superclass No.**|**Superclass**|**Classes**|\n",
    "|:-:|:-:|:-:|\n",
    "|1|aquatic mammals|beaver, dolphin, otter, seal, whale|\n",
    "|2|fish|aquarium fish, flatfish, ray, shark, trout|\n",
    "|3|flowers|orchids, poppies, roses, sunflowers, tulips|\n",
    "|4|food containers|bottles, bowls, cans, cups, plates|\n",
    "|5|fruit and vegetables|apples, mushrooms, oranges, pears, sweet peppers|\n",
    "|6|household electrical devices|clock, computer keyboard, lamp, telephone, television|\n",
    "|7|household furniture|bed, chair, couch, table, wardrobe|\n",
    "|8|insects|bee, beetle, butterfly, caterpillar, cockroach|\n",
    "|9|large carnivores|bear, leopard, lion, tiger, wolf|\n",
    "|10|large man-made outdoor things|bridge, castle, house, road, skyscraper|\n",
    "|11|large natural outdoor scenes|cloud, forest, mountain, plain, sea|\n",
    "|12|large omnivores and herbivores|camel, cattle, chimpanzee, elephant, kangaroo|\n",
    "|13|medium-sized mammals|fox, porcupine, possum, raccoon, skunk|\n",
    "|14|non-insect invertebrates|crab, lobster, snail, spider, worm|\n",
    "|15|people|baby, boy, girl, man, woman|\n",
    "|16|reptiles|crocodile, dinosaur, lizard, snake, turtle|\n",
    "|17|small mammals|hamster, mouse, rabbit, shrew, squirrel|\n",
    "|18|trees|maple, oak, palm, pine, willow|\n",
    "|19|vehicles 1|bicycle, bus, motorcycle, pickup truck, train|\n",
    "|20|vehicles 2|lawn-mower, rocket, streetcar, tank, tractor|\n",
    "\n",
    "The labels are kept in the meta file. Therefore, we will extract the label names (fine and coarse) from the meta file directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the labels\n",
    "label = unpickle('data/cifar-100-python/meta')\n",
    "print(f'Label Keys: {label.keys()}')\n",
    "print('-'*20)\n",
    "print(f'Label Fine Label Names: {label[b\"fine_label_names\"]}')\n",
    "print('-'*20)\n",
    "print(f'Label Coarse Label Names: {label[b\"coarse_label_names\"]}')\n",
    "\n",
    "label_fine = label[b\"fine_label_names\"]\n",
    "label_coarse = label[b\"coarse_label_names\"]\n",
    "\n",
    "# Decode labels\n",
    "label_fine = [x.decode('utf-8') for x in label_fine]\n",
    "label_coarse = [x.decode('utf-8') for x in label_coarse]\n",
    "\n",
    "label2id = {label_fine[i]: i for i in range(len(label_fine))}\n",
    "id2label = {i: label_fine[i] for i in range(len(label_fine))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train[b\"data\"]\n",
    "train_coarse_labels = train[b\"coarse_labels\"]\n",
    "train_fine_labels = train[b\"fine_labels\"]\n",
    "train_batch_label = train[b\"batch_label\"]\n",
    "\n",
    "test_data = test[b\"data\"]\n",
    "test_coarse_labels = test[b\"coarse_labels\"]\n",
    "test_fine_labels = test[b\"fine_labels\"]\n",
    "test_batch_label = test[b\"batch_label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0], train_coarse_labels[0], train_fine_labels[0], train_batch_label, test_data[0], test_coarse_labels[0], test_fine_labels[0], test_batch_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Train data min: {train_data.min()}\\nTrain data max: {train_data.max()}')\n",
    "print(f'Test data min: {test_data.min()}\\nTest data max: {test_data.max()}')\n",
    "print('-'*20)\n",
    "print(f'Train data mean: {train_data.mean()}\\nTrain data std: {train_data.std()}')\n",
    "print(f'Test data mean: {test_data.mean()}\\nTest data std: {test_data.std()}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Preprocessing**\n",
    "\n",
    "Since the image data's range is (0, 255), we will normalize it to (0, 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data\n",
    "train_data = train_data.reshape(50000, 32, 32, 3)\n",
    "test_data = test_data.reshape(10000, 32, 32, 3)\n",
    "\n",
    "print(f'Train Data Shape: {train_data.shape}\\nTest Data Shape: {test_data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "train_data, test_data = train_data/255.0, test_data/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(data, datalabel, fulllabel):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i in range(25):\n",
    "        plt.subplot(5, 5, i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(data[i])\n",
    "        plt.xlabel(fulllabel[datalabel[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(train_data, train_fine_labels, label_fine)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like we reshaped the data wrongly. We will try to reshape it again by separating each color profile (R, G, B) and restack them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train[b'data']\n",
    "test_data = test[b'data']\n",
    "\n",
    "train_data_R = train_data[:, :1024].reshape(50000, 32, 32)\n",
    "train_data_G = train_data[:, 1024:2048].reshape(50000, 32, 32)\n",
    "train_data_B = train_data[:, 2048:].reshape(50000, 32, 32)\n",
    "\n",
    "test_data_R = test_data[:, :1024].reshape(10000, 32, 32)\n",
    "test_data_G = test_data[:, 1024:2048].reshape(10000, 32, 32)\n",
    "test_data_B = test_data[:, 2048:].reshape(10000, 32, 32)\n",
    "\n",
    "# Stack the data\n",
    "train_data = np.stack((train_data_R, train_data_G, train_data_B), axis=3)\n",
    "test_data = np.stack((test_data_R, test_data_G, test_data_B), axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(train_data, train_fine_labels, label_fine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Train Data Shape: {train_data.shape}\\nTest Data Shape: {test_data.shape}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason why we have to separate them like this instead of directly reshaping them is because the data were flatten before saving as text file.\n",
    "\n",
    "Credit to: https://www.kaggle.com/code/yipengzhou3/cifar100-pytorch for doing the same 'wrong' approach to reshaping the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_data, train_fine_labels\n",
    "X_test, y_test = test_data, test_fine_labels\n",
    "\n",
    "num_classes = 100\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform data to Tensor\n",
    "transform_data = transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the augmentation\n",
    "augmented_train_data = []\n",
    "augmented_train_label = []\n",
    "for image, label in zip(X_train, y_train_encoded):\n",
    "    augmented_train_data.append(transform_data(image))\n",
    "    augmented_train_label.append(label)\n",
    "\n",
    "augmented_test_data = []\n",
    "augmented_test_label = []\n",
    "for image, label in zip(X_test, y_test_encoded):\n",
    "    augmented_test_data.append(transform_data(image))\n",
    "    augmented_test_label.append(label)\n",
    "\n",
    "augmented_train_data = torch.stack(augmented_train_data)\n",
    "augmented_test_data = torch.stack(augmented_test_data)\n",
    "\n",
    "print(f'Augmented Train Data Shape: {augmented_train_data.shape}\\nAugmented Test Data Shape: {augmented_test_data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "train_dataset = TensorDataset(augmented_train_data, torch.Tensor(augmented_train_label))\n",
    "test_dataset = TensorDataset(augmented_test_data, torch.Tensor(augmented_test_label))\n",
    "\n",
    "# Create the dataloader\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.modeling_outputs import ImageClassifierOutputWithNoAttention\n",
    "# Training\n",
    "def train_model(models, modelnames, criterion, optimizer, scheduler, num_epochs):\n",
    "\n",
    "    # Store the loss and accuracy\n",
    "    traintestData = {}\n",
    "\n",
    "    ### Train the model ###\n",
    "    for model, modelname in zip(models, modelnames):\n",
    "        train_loss = []\n",
    "        test_acc = []\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            for _, batch in enumerate(train_loader):\n",
    "                images = batch[0].to(device)\n",
    "                labels = batch[1].to(device).long()\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                outputs = model(images)\n",
    "\n",
    "                # Convert outputs to tensor\n",
    "                if isinstance(outputs, ImageClassifierOutputWithNoAttention):\n",
    "                    outputs = outputs.logits\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * images.size(0)\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "            ### Test the model ###\n",
    "\n",
    "            model.eval()\n",
    "            num_correct = 0\n",
    "            total = 0\n",
    "            with torch.no_grad():\n",
    "                for _, batch in enumerate(test_loader):\n",
    "                    images = batch[0].to(device)\n",
    "                    labels = batch[1].to(device).long()\n",
    "\n",
    "                    outputs = model(images)\n",
    "\n",
    "                    if isinstance(outputs, ImageClassifierOutputWithNoAttention):\n",
    "                        outputs = outputs.logits\n",
    "                    \n",
    "                    _, predicted = torch.max(outputs, dim=1)\n",
    "                    total += labels.size(0)\n",
    "                    num_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            epoch_loss = running_loss/len(train_loader.dataset)\n",
    "\n",
    "            # Save the loss and accuracy for train and test set\n",
    "            train_loss.append(epoch_loss)\n",
    "            test_acc.append(num_correct/total)\n",
    "\n",
    "            print(f'ConvNeXt {modelname} -> Epoch: {epoch+1}/{num_epochs} | Loss: {epoch_loss} | Test Accuracy: {num_correct/total}')\n",
    "\n",
    "        traintestData[f'Training Loss_{modelname}'] = train_loss\n",
    "        traintestData[f'Test Accuracy_{modelname}'] = test_acc\n",
    "\n",
    "    return traintestData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lossAccPlot(lossAccDict, modelnames, cutoff=0):\n",
    "    names = ['Training Loss', 'Test Accuracy']\n",
    "    label = ['Loss', 'Accuracy']\n",
    "\n",
    "    _, axes = plt.subplots(2, 2, figsize=(20, 10))\n",
    "    for ax, modelname in zip(range(len(axes)), modelnames):\n",
    "        for i in range(len(names)):\n",
    "            val = lossAccDict[f'{names[i]}_{modelname}']\n",
    "            axes[ax][i].plot(val, label=names[i])\n",
    "            if cutoff != 0:\n",
    "                # Plot cutoff line\n",
    "                axes[ax][i].axvline(x=cutoff, color='r', linestyle='--')\n",
    "            axes[ax][i].set_xlabel('Epoch')\n",
    "            axes[ax][i].set_ylabel(label[i])\n",
    "            axes[ax][i].legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ConvNeXt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForImageClassification\n",
    "\n",
    "convnext_tiny = AutoModelForImageClassification.from_pretrained(\"facebook/convnext-tiny-224\",\n",
    "                                                        num_labels=len(label_fine),\n",
    "                                                        label2id=label2id,\n",
    "                                                        id2label=id2label,\n",
    "                                                        ignore_mismatched_sizes=True)\n",
    "\n",
    "convnext_tiny_wd = AutoModelForImageClassification.from_pretrained(\"facebook/convnext-tiny-224\",\n",
    "                                                        num_labels=len(label_fine),\n",
    "                                                        label2id=label2id,\n",
    "                                                        id2label=id2label,\n",
    "                                                        ignore_mismatched_sizes=True)\n",
    "\n",
    "convnext_base = AutoModelForImageClassification.from_pretrained(\"facebook/convnext-base-224\",\n",
    "                                                        num_labels=len(label_fine),\n",
    "                                                        label2id=label2id,\n",
    "                                                        id2label=id2label,\n",
    "                                                        ignore_mismatched_sizes=True)\n",
    "\n",
    "convnext_base_wd = AutoModelForImageClassification.from_pretrained(\"facebook/convnext-base-224\",\n",
    "                                                        num_labels=len(label_fine),\n",
    "                                                        label2id=label2id,\n",
    "                                                        id2label=id2label,\n",
    "                                                        ignore_mismatched_sizes=True)\n",
    "\n",
    "convnext_large = AutoModelForImageClassification.from_pretrained(\"facebook/convnext-large-224\",\n",
    "                                                        num_labels=len(label_fine),\n",
    "                                                        label2id=label2id,\n",
    "                                                        id2label=id2label,\n",
    "                                                        ignore_mismatched_sizes=True)\n",
    "\n",
    "convnext_large_wd = AutoModelForImageClassification.from_pretrained(\"facebook/convnext-large-224\",\n",
    "                                                        num_labels=len(label_fine),\n",
    "                                                        label2id=label2id,\n",
    "                                                        id2label=id2label,\n",
    "                                                        ignore_mismatched_sizes=True)\n",
    "\n",
    "convnext_tiny.to(device)\n",
    "convnext_tiny_wd.to(device)\n",
    "convnext_base.to(device)\n",
    "convnext_base_wd.to(device)\n",
    "convnext_large.to(device)\n",
    "convnext_large_wd.to(device)\n",
    "\n",
    "models = [convnext_tiny, convnext_base, convnext_large]\n",
    "modelnames = ['Tiny', 'Base', 'Large']\n",
    "models_wd = [convnext_tiny_wd, convnext_base_wd, convnext_large_wd]\n",
    "modelnames_wd = ['TinyWD', 'BaseWD', 'LargeWD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.AdamW([{'params': model.parameters()} for model in models], lr=5e-5)\n",
    "optimizer_wd = torch.optim.AdamW([{'params': model.parameters()} for model in models_wd], lr=5e-5, weight_decay=1e-8)\n",
    "\n",
    "# Learning rate scheduler\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noWDDict = train_model(models, modelnames, criterion, optimizer, lr_scheduler, num_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossAccPlot(noWDDict, modelnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WDDict = train_model(models_wd, modelnames_wd, criterion, optimizer_wd, lr_scheduler, num_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossAccPlot(WDDict, modelnames_wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get last and max test accuracy\n",
    "for modelname in modelnames:\n",
    "    print(f'ConvNeXt {modelname} -> Last Test Accuracy: {noWDDict[f\"Test Accuracy_{modelname}\"][-1]} | Max Test Accuracy: {max(noWDDict[f\"Test Accuracy_{modelname}\"])} (Epoch:{noWDDict[f\"Test Accuracy_{modelname}\"].index(max(noWDDict[f\"Test Accuracy_{modelname}\"]))})')\n",
    "\n",
    "print('-'*50)\n",
    "\n",
    "for modelname in modelnames_wd:\n",
    "    print(f'ConvNeXt {modelname} -> Last Test Accuracy: {WDDict[f\"Test Accuracy_{modelname}\"][-1]} | Max Test Accuracy: {max(WDDict[f\"Test Accuracy_{modelname}\"])} (Epoch:{WDDict[f\"Test Accuracy_{modelname}\"].index(max(WDDict[f\"Test Accuracy_{modelname}\"]))})')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the result above, applying weight decay to the optimizer improved the performance by 1%. We will come back to visit the preferrable weight decay value and learning rate after we try augmenting the data.\n",
    "\n",
    "We will stick with using learning rate at 5e-5 and weight decay at 1e-8, which is from the fine-tuning setting section of ConvNeXt's paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(models):\n",
    "    for model, modelname in zip(models, modelnames):\n",
    "        torch.save(model.state_dict(), f'models/ConvNeXt_{modelname}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(models_wd)\n",
    "\n",
    "del models, models_wd\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Augmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_data, train_fine_labels\n",
    "X_test, y_test = test_data, test_fine_labels\n",
    "\n",
    "num_classes = 100\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform data to Tensor\n",
    "transform_data = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the augmentation\n",
    "augmented_train_data = []\n",
    "augmented_train_label = []\n",
    "for image, label in zip(X_train, y_train_encoded):\n",
    "    augmented_train_data.append(transform_data(image))\n",
    "    augmented_train_label.append(label)\n",
    "\n",
    "augmented_test_data = []\n",
    "augmented_test_label = []\n",
    "for image, label in zip(X_test, y_test_encoded):\n",
    "    augmented_test_data.append(transform_data(image))\n",
    "    augmented_test_label.append(label)\n",
    "\n",
    "augmented_train_data = torch.stack(augmented_train_data)\n",
    "augmented_test_data = torch.stack(augmented_test_data)\n",
    "\n",
    "print(f'Augmented Train Data Shape: {augmented_train_data.shape}\\nAugmented Test Data Shape: {augmented_test_data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "train_dataset = TensorDataset(augmented_train_data, torch.Tensor(augmented_train_label))\n",
    "test_dataset = TensorDataset(augmented_test_data, torch.Tensor(augmented_test_label))\n",
    "\n",
    "# Create the dataloader\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForImageClassification\n",
    "\n",
    "convnext_tiny = AutoModelForImageClassification.from_pretrained(\"facebook/convnext-tiny-224\",\n",
    "                                                        num_labels=len(label_fine),\n",
    "                                                        label2id=label2id,\n",
    "                                                        id2label=id2label,\n",
    "                                                        ignore_mismatched_sizes=True)\n",
    "\n",
    "convnext_base = AutoModelForImageClassification.from_pretrained(\"facebook/convnext-base-224\",\n",
    "                                                        num_labels=len(label_fine),\n",
    "                                                        label2id=label2id,\n",
    "                                                        id2label=id2label,\n",
    "                                                        ignore_mismatched_sizes=True)\n",
    "\n",
    "convnext_large = AutoModelForImageClassification.from_pretrained(\"facebook/convnext-large-224\",\n",
    "                                                        num_labels=len(label_fine),\n",
    "                                                        label2id=label2id,\n",
    "                                                        id2label=id2label,\n",
    "                                                        ignore_mismatched_sizes=True)\n",
    "\n",
    "\n",
    "convnext_tiny.to(device)\n",
    "convnext_base.to(device)\n",
    "convnext_large.to(device)\n",
    "\n",
    "models = [convnext_tiny, convnext_base, convnext_large]\n",
    "modelnames = ['Tiny', 'Base', 'Large']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.AdamW([{'params': model.parameters()} for model in models], lr=5e-5, weight_decay=1e-8)\n",
    "\n",
    "# Learning rate scheduler\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "augmentDataModel = train_model(models, modelnames, criterion, optimizer, lr_scheduler, num_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossAccPlot(augmentDataModel, modelnames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu210",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
